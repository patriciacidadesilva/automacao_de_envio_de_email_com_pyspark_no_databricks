## ğŸ“§ Alertas Operacionais Automatizados com PySpark no Databricks

### ğŸ¯ VisÃ£o Geral

Este projeto demonstra uma **automaÃ§Ã£o de envio de e-mails operacionais**, construÃ­da com **PySpark no Databricks**, cujo objetivo Ã© identificar **documentos pendentes de processamento** acima de um SLA definido e **notificar automaticamente os responsÃ¡veis**.

Todas as tabelas, colunas, domÃ­nios e regras de negÃ³cio utilizadas neste repositÃ³rio sÃ£o **fictÃ­cias** e existem **exclusivamente para fins de demonstraÃ§Ã£o tÃ©cnica e portfÃ³lio**.

> **Resumo executivo:**  
> dados distribuÃ­dos â†’ regras de negÃ³cio â†’ exceÃ§Ã£o â†’ notificaÃ§Ã£o automÃ¡tica

---

### ğŸ§  Contexto de NegÃ³cio (FictÃ­cio)

**Empresa:** Acme Corp  
**Ãrea:** OperaÃ§Ãµes Financeiras e Administrativas  

**Desafio:**  
Documentos operacionais pendentes por longos perÃ­odos geram gargalos, retrabalho e impactos em processos downstream.
Antes desta soluÃ§Ã£o, o acompanhamento dessas pendÃªncias dependia de verificaÃ§Ãµes manuais e comunicaÃ§Ãµes reativas.

---

### ğŸš€ SoluÃ§Ã£o

Um **pipeline hÃ­brido**, com responsabilidades bem definidas:

- **PySpark** para processamento distribuÃ­do e aplicaÃ§Ã£o das regras de negÃ³cio  
- **Python** para orquestraÃ§Ã£o, geraÃ§Ã£o de Excel e envio de e-mails  
- **Databricks** como plataforma de execuÃ§Ã£o, seguranÃ§a e agendamento  

A soluÃ§Ã£o:
- identifica documentos pendentes acima do SLA
- resolve dinamicamente o e-mail do responsÃ¡vel
- gera um relatÃ³rio estruturado em Excel
- envia notificaÃ§Ãµes automÃ¡ticas com evidÃªncia anexada

---

### ğŸ—ï¸ Arquitetura (Alto NÃ­vel)

1. Leitura das tabelas fato e dimensÃ£o via Spark  
2. NormalizaÃ§Ã£o de usuÃ¡rios e datas  
3. Enriquecimento com informaÃ§Ãµes de e-mail  
4. AplicaÃ§Ã£o de filtros e regras de exclusÃ£o  
5. Coleta controlada de dados para o driver  
6. GeraÃ§Ã£o do arquivo Excel  
7. Envio de e-mail via SMTP autenticado  

---

### ğŸ§© Tecnologias Utilizadas

- Databricks  
- Apache Spark / PySpark  
- Python 3  
- Pandas  
- xlsxwriter  
- SMTP (Office 365)  
- Databricks Secrets  

---

### ğŸ“‚ Fontes de Dados (FictÃ­cias)

| Tipo | Tabela |
|---|---|
| Fato | `analytics.ops_core.fact_documents_backlog` |
| DimensÃ£o | `analytics.ops_core.dim_users` |

---

### ğŸ§± Modelo de Dados (Simplificado)

#### Fato: `fact_documents_backlog`

| Coluna | DescriÃ§Ã£o |
|---|---|
| document_id | Identificador Ãºnico do documento |
| document_number | NÃºmero do documento |
| document_key | Chave Ãºnica |
| document_amount | Valor total |
| issue_date | Data de emissÃ£o |
| due_date | Data de vencimento |
| client_tax_id | Identificador do cliente |
| client_name | Nome do cliente |
| supplier_tax_id | Identificador do fornecedor |
| supplier_name | Nome do fornecedor |
| processing_status | Status de processamento |
| processing_days | Dias em pendÃªncia |
| document_link | Link de referÃªncia |
| document_category | Categoria do documento |
| resolution_type | Tipo de conclusÃ£o |
| responsible_area | Ãrea responsÃ¡vel |
| request_owner | Dono do documento |
| task_name | Tarefa atual |
| processing_flag | Indicador de processamento |
| business_unit | Unidade de negÃ³cio |
| cost_center | Centro de custo |

---

#### DimensÃ£o: `dim_users`

| Coluna | DescriÃ§Ã£o |
|---|---|
| username | Identificador do usuÃ¡rio |
| email | E-mail do usuÃ¡rio |

---

### ğŸ“ Regras de NegÃ³cio (FictÃ­cias)

- Considera apenas documentos:
  - com `processing_flag = 'Pending'`
  - com data de emissÃ£o vÃ¡lida
  - pendentes hÃ¡ mais de **15 dias**
  - pertencentes a um centro de custo especÃ­fico (`D010`)
- Exclui tarefas tÃ©cnicas ou automatizadas
- ResoluÃ§Ã£o de e-mail:
  - prioritariamente via join com a dimensÃ£o de usuÃ¡rios
  - fallback por regras baseadas na Ã¡rea responsÃ¡vel

---

### ğŸ“Š SaÃ­das (Output)

- **RelatÃ³rio Excel (.xlsx)** com os documentos pendentes
- **E-mail automÃ¡tico** contendo:
  - assunto padronizado
  - corpo explicativo orientado Ã  aÃ§Ã£o
  - relatÃ³rio anexado

---

### ğŸ” SeguranÃ§a e GovernanÃ§a

- Credenciais armazenadas via **Databricks Secrets**
- Remetente alinhado ao usuÃ¡rio autenticado (anti-spoofing)
- Limite explÃ­cito de linhas antes do `toPandas()` para proteÃ§Ã£o do driver
- SeparaÃ§Ã£o clara entre processamento distribuÃ­do e execuÃ§Ã£o local

---

### âš™ï¸ ConfiguraÃ§Ã£o

ParÃ¢metros ajustÃ¡veis no cÃ³digo:

```python
MAX_LINHAS_EXCEL = 2000
SMTP_SERVER = "smtp.office365.com"
SMTP_PORT = 587
``` 

---

### Secrets necessÃ¡rios no Databricks:

- USER
- PASSWORD

---

### ğŸ•’ ExecuÃ§Ã£o

O notebook pode ser:
- executado manualmente para testes
- agendado como Databricks Job
- integrado a um fluxo maior de monitoramento operacional

---

### ğŸ“ˆ BenefÃ­cios

- Monitoramento proativo de pendÃªncias
- ReduÃ§Ã£o de trabalho manual
- ComunicaÃ§Ã£o padronizada e auditÃ¡vel
- Escalabilidade com Spark
- CÃ³digo limpo, governÃ¡vel e pronto para produÃ§Ã£o

---

### ğŸ“ Estrutura do RepositÃ³rio

```text
.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ alertas_operacionais_pyspark_databricks.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

### ğŸ‘©â€ğŸ’» Autoria

Projeto desenvolvido com foco em **Engenharia de Dados**, **Analytics Engineering** e **DataOps**, utilizando PySpark no Databricks como base tecnolÃ³gica.
Este projeto utiliza nomes, tabelas e regras de negÃ³cio fictÃ­cias.
NÃ£o representa sistemas ou dados reais de nenhuma organizaÃ§Ã£o.

---

### ğŸ§­ PrÃ³ximos Passos (Roadmap)

- ParametrizaÃ§Ã£o do SLA e centro de custo
- GeraÃ§Ã£o do relatÃ³rio em storage (em vez de anexo)
- IntegraÃ§Ã£o com ferramentas de alerta (Teams / Slack)
- Observabilidade e logs estruturados
- TransformaÃ§Ã£o em Databricks Job com SLA e alertas de falha
